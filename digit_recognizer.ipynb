{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PEtEFFv0g23A"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.layers import Conv2D, Dense, MaxPool2D, BatchNormalization, Flatten, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZvDr1jF4hJ-s",
    "outputId": "5cce3d24-8c5e-43c3-ed14-3c9d56b2747a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 88,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the training and test data\n",
    "df = pd.read_csv('dataset/train.csv')\n",
    "df_test = pd.read_csv('dataset/test.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "colab_type": "code",
    "id": "OfiDoEbfiQ_j",
    "outputId": "504c933b-8b29-42af-bda0-6835cffabe03"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>pixel11</th>\n",
       "      <th>pixel12</th>\n",
       "      <th>pixel13</th>\n",
       "      <th>pixel14</th>\n",
       "      <th>pixel15</th>\n",
       "      <th>pixel16</th>\n",
       "      <th>pixel17</th>\n",
       "      <th>pixel18</th>\n",
       "      <th>pixel19</th>\n",
       "      <th>pixel20</th>\n",
       "      <th>pixel21</th>\n",
       "      <th>pixel22</th>\n",
       "      <th>pixel23</th>\n",
       "      <th>pixel24</th>\n",
       "      <th>pixel25</th>\n",
       "      <th>pixel26</th>\n",
       "      <th>pixel27</th>\n",
       "      <th>pixel28</th>\n",
       "      <th>pixel29</th>\n",
       "      <th>pixel30</th>\n",
       "      <th>pixel31</th>\n",
       "      <th>pixel32</th>\n",
       "      <th>pixel33</th>\n",
       "      <th>pixel34</th>\n",
       "      <th>pixel35</th>\n",
       "      <th>pixel36</th>\n",
       "      <th>pixel37</th>\n",
       "      <th>pixel38</th>\n",
       "      <th>pixel39</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel744</th>\n",
       "      <th>pixel745</th>\n",
       "      <th>pixel746</th>\n",
       "      <th>pixel747</th>\n",
       "      <th>pixel748</th>\n",
       "      <th>pixel749</th>\n",
       "      <th>pixel750</th>\n",
       "      <th>pixel751</th>\n",
       "      <th>pixel752</th>\n",
       "      <th>pixel753</th>\n",
       "      <th>pixel754</th>\n",
       "      <th>pixel755</th>\n",
       "      <th>pixel756</th>\n",
       "      <th>pixel757</th>\n",
       "      <th>pixel758</th>\n",
       "      <th>pixel759</th>\n",
       "      <th>pixel760</th>\n",
       "      <th>pixel761</th>\n",
       "      <th>pixel762</th>\n",
       "      <th>pixel763</th>\n",
       "      <th>pixel764</th>\n",
       "      <th>pixel765</th>\n",
       "      <th>pixel766</th>\n",
       "      <th>pixel767</th>\n",
       "      <th>pixel768</th>\n",
       "      <th>pixel769</th>\n",
       "      <th>pixel770</th>\n",
       "      <th>pixel771</th>\n",
       "      <th>pixel772</th>\n",
       "      <th>pixel773</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  ...  pixel780  pixel781  pixel782  pixel783\n",
       "0       0       0       0       0  ...         0         0         0         0\n",
       "1       0       0       0       0  ...         0         0         0         0\n",
       "2       0       0       0       0  ...         0         0         0         0\n",
       "3       0       0       0       0  ...         0         0         0         0\n",
       "4       0       0       0       0  ...         0         0         0         0\n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "HXX8BUMbi9M_",
    "outputId": "70d09695-86b3-4ba8-b41e-8e8b228627ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert dataframe to input(X_train) and output label(Y_train) format where input is the values of all the 28x28 pixels in all the images and output label is the actual digit the image represents.\n",
    "Y_train = df['label']\n",
    "X_train = df.drop(labels=['label'],axis=1)\n",
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xNrbpen_kprk",
    "outputId": "c324be33-61ab-4e47-f1a2-26f4adc6330e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check null values in the labels\n",
    "Y_train.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "p3twKv41lFGQ",
    "outputId": "f1e92fb7-de8b-4041-e894-e66fa12c0b82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check null values in the pixel data\n",
    "X_train.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JNdgYIXPnuC8"
   },
   "outputs": [],
   "source": [
    "#Normalise the data\n",
    "X_train = X_train/255\n",
    "df_test = df_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ApW_DdJ8rj0S"
   },
   "source": [
    "The CNN Models converge faster on data in (0,1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XmQ7_pxLpSa_"
   },
   "outputs": [],
   "source": [
    "#Convert pixel data to 28x28x1 image\n",
    "X_train_reshape = X_train.values.reshape(-1,28,28,1)\n",
    "df_test = df_test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Q31PmuRrSlh"
   },
   "source": [
    " The data of each image is given as 1D array of 784 values. This 1D array is converted to 3D greyscale image using reshape. The reshape function has first param as -1 as the number of rows are unknown. The dimension of each image is 28x28x1. The 1 represents number of channels in greyscale image. For RGB the number of channels is 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "C3YcRzyFwYaR",
    "outputId": "719483d2-4cfc-41aa-8e99-0dfa9f79397c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 28, 28, 1)\n",
      "(28000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train_reshape))\n",
    "print(np.shape(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bgRFtiKK24N4"
   },
   "outputs": [],
   "source": [
    "#Convert categorical data to one hot encoding using keras\n",
    "Y_train = to_categorical(Y_train, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CpEMIrj8rdIW"
   },
   "source": [
    "The digits 0-9 repesent categorical data. They are converted to one-hot-encoded vectors. This is done to achieve output in the form of probabilites for each class. The class with maximum probability is given as predicted output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "T8bh1Tn53TLQ",
    "outputId": "a9942ab5-b313-408e-cd0c-b4c4a4843397"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k1u719HwlO9I"
   },
   "outputs": [],
   "source": [
    "#Create test dataset from the training data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train_reshape, Y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "wNabgYG89LUy",
    "outputId": "6d2a7b3c-ad97-48f9-b416-2978cec5e7de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (37800, 28, 28, 1)\n",
      "X_test shape: (4200, 28, 28, 1)\n",
      "Y_train shape: (37800, 10)\n",
      "Y_test shape: (4200, 10)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print('Y_test shape:', Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0tf5j1brtHps"
   },
   "source": [
    "**CNN Model**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Bedhd7k1pCH"
   },
   "outputs": [],
   "source": [
    "#CNN Model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu', input_shape=(28, 28, 1), padding='same'))\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation = \"relu\"))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eBqMvJlD6mC3"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "cBs1bacS8POu",
    "outputId": "2fb5705b-7aa5-425d-cecd-0b4854d8977a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                200736    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 293,738\n",
      "Trainable params: 293,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LrnNZVyG1NdY"
   },
   "source": [
    "Early stopping is used for the model. It enables us to specifiy more number of epoches for training but it stops training once the model doesn't improve further with a patience of a specified number of epoches.\n",
    "Model Checkpoints are used to save the model weights after each epoch if the val_loss is decreased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X5tDGVXpS2T_"
   },
   "outputs": [],
   "source": [
    "# callbacks = [ModelCheckpoint('/content/drive/My Drive/Colab Notebooks/digit-recognizer/best.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False),\n",
    "#              EarlyStopping(patience=3, monitor='val_loss', verbose=1)]\n",
    "callbacks = [ModelCheckpoint('model/best.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "EbZxTbKg8Rfn",
    "outputId": "79a0bb9a-e878-4981-dd1e-7fd5986aa836"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34020 samples, validate on 3780 samples\n",
      "Epoch 1/30\n",
      "34020/34020 [==============================] - 6s 169us/step - loss: 0.0118 - acc: 0.9961 - val_loss: 0.0629 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06292, saving model to /content/drive/My Drive/Colab Notebooks/digit-recognizer/best.h5\n",
      "Epoch 2/30\n",
      "34020/34020 [==============================] - 6s 170us/step - loss: 0.0097 - acc: 0.9971 - val_loss: 0.0632 - val_acc: 0.9862\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06292\n",
      "Epoch 3/30\n",
      "34020/34020 [==============================] - 6s 171us/step - loss: 0.0082 - acc: 0.9972 - val_loss: 0.0628 - val_acc: 0.9868\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.06292 to 0.06277, saving model to /content/drive/My Drive/Colab Notebooks/digit-recognizer/best.h5\n",
      "Epoch 4/30\n",
      "34020/34020 [==============================] - 6s 168us/step - loss: 0.0082 - acc: 0.9971 - val_loss: 0.0627 - val_acc: 0.9868\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.06277 to 0.06274, saving model to /content/drive/My Drive/Colab Notebooks/digit-recognizer/best.h5\n",
      "Epoch 5/30\n",
      "34020/34020 [==============================] - 6s 169us/step - loss: 0.0069 - acc: 0.9979 - val_loss: 0.0646 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06274\n",
      "Epoch 6/30\n",
      "34020/34020 [==============================] - 6s 169us/step - loss: 0.0074 - acc: 0.9976 - val_loss: 0.0639 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06274\n",
      "Epoch 7/30\n",
      "34020/34020 [==============================] - 6s 167us/step - loss: 0.0077 - acc: 0.9974 - val_loss: 0.0533 - val_acc: 0.9878\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.06274 to 0.05327, saving model to /content/drive/My Drive/Colab Notebooks/digit-recognizer/best.h5\n",
      "Epoch 8/30\n",
      "34020/34020 [==============================] - 6s 169us/step - loss: 0.0036 - acc: 0.9991 - val_loss: 0.0687 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05327\n",
      "Epoch 9/30\n",
      "34020/34020 [==============================] - 6s 169us/step - loss: 0.0072 - acc: 0.9981 - val_loss: 0.0611 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05327\n",
      "Epoch 10/30\n",
      "34020/34020 [==============================] - 6s 169us/step - loss: 0.0048 - acc: 0.9987 - val_loss: 0.0661 - val_acc: 0.9878\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05327\n",
      "Epoch 11/30\n",
      "34020/34020 [==============================] - 6s 168us/step - loss: 0.0047 - acc: 0.9987 - val_loss: 0.0584 - val_acc: 0.9899\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.05327\n",
      "Epoch 12/30\n",
      "34020/34020 [==============================] - 6s 169us/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0739 - val_acc: 0.9897\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.05327\n",
      "Epoch 13/30\n",
      "34020/34020 [==============================] - 6s 172us/step - loss: 0.0072 - acc: 0.9980 - val_loss: 0.0430 - val_acc: 0.9892\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.05327 to 0.04296, saving model to /content/drive/My Drive/Colab Notebooks/digit-recognizer/best.h5\n",
      "Epoch 14/30\n",
      "34020/34020 [==============================] - 6s 173us/step - loss: 0.0046 - acc: 0.9986 - val_loss: 0.0629 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.04296\n",
      "Epoch 15/30\n",
      "34020/34020 [==============================] - 6s 176us/step - loss: 0.0036 - acc: 0.9990 - val_loss: 0.0594 - val_acc: 0.9897\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.04296\n",
      "Epoch 16/30\n",
      "34020/34020 [==============================] - 6s 171us/step - loss: 0.0035 - acc: 0.9990 - val_loss: 0.0621 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.04296\n",
      "Epoch 17/30\n",
      "34020/34020 [==============================] - 6s 170us/step - loss: 0.0035 - acc: 0.9992 - val_loss: 0.0711 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.04296\n",
      "Epoch 18/30\n",
      "34020/34020 [==============================] - 6s 171us/step - loss: 0.0055 - acc: 0.9985 - val_loss: 0.0587 - val_acc: 0.9897\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.04296\n",
      "Epoch 19/30\n",
      "34020/34020 [==============================] - 6s 169us/step - loss: 0.0050 - acc: 0.9985 - val_loss: 0.0483 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.04296\n",
      "Epoch 20/30\n",
      "34020/34020 [==============================] - 6s 168us/step - loss: 0.0045 - acc: 0.9985 - val_loss: 0.0813 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.04296\n",
      "Epoch 21/30\n",
      "34020/34020 [==============================] - 6s 168us/step - loss: 0.0029 - acc: 0.9994 - val_loss: 0.0812 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.04296\n",
      "Epoch 22/30\n",
      "34020/34020 [==============================] - 6s 168us/step - loss: 0.0044 - acc: 0.9989 - val_loss: 0.0604 - val_acc: 0.9907\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.04296\n",
      "Epoch 23/30\n",
      "34020/34020 [==============================] - 6s 169us/step - loss: 0.0022 - acc: 0.9993 - val_loss: 0.0674 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.04296\n",
      "Epoch 24/30\n",
      "34020/34020 [==============================] - 6s 170us/step - loss: 0.0045 - acc: 0.9990 - val_loss: 0.0848 - val_acc: 0.9894\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.04296\n",
      "Epoch 25/30\n",
      "34020/34020 [==============================] - 6s 168us/step - loss: 0.0023 - acc: 0.9995 - val_loss: 0.1088 - val_acc: 0.9865\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.04296\n",
      "Epoch 26/30\n",
      "34020/34020 [==============================] - 6s 170us/step - loss: 0.0050 - acc: 0.9989 - val_loss: 0.0879 - val_acc: 0.9907\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.04296\n",
      "Epoch 27/30\n",
      "34020/34020 [==============================] - 6s 170us/step - loss: 0.0045 - acc: 0.9989 - val_loss: 0.0901 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.04296\n",
      "Epoch 28/30\n",
      "34020/34020 [==============================] - 6s 169us/step - loss: 0.0029 - acc: 0.9993 - val_loss: 0.1148 - val_acc: 0.9862\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.04296\n",
      "Epoch 29/30\n",
      "34020/34020 [==============================] - 6s 168us/step - loss: 0.0025 - acc: 0.9994 - val_loss: 0.0836 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.04296\n",
      "Epoch 30/30\n",
      "34020/34020 [==============================] - 6s 167us/step - loss: 0.0038 - acc: 0.9991 - val_loss: 0.1059 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.04296\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=30, validation_split=0.1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JnzEYD0GOZI1",
    "outputId": "c4cad328-7564-476e-b08d-024345cd1185"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.999, Test: 0.991\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(X_train, Y_train, verbose=0)\n",
    "_, test_acc = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "tOMoBGo5OeJe",
    "outputId": "806b05a6-9796-4cab-e297-9537740b1007"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAD8CAYAAACW/ATfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUiFAg71SSoWA/w/rh6WjXkjL2wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C3EHjQ7j82un"
   },
   "outputs": [],
   "source": [
    "# predict results\n",
    "results = model.predict(df_test)\n",
    "# select the index with maximum probability\n",
    "results = np.argmax(results,axis = 1)\n",
    "results = pd.Series(results,name=\"Label\")\n",
    "submit = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "submit.to_csv(\"submission/mnist_predictions.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"submission/mnist_submission.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RLmKtY89En4i"
   },
   "source": [
    "**Data Augmentation**\n",
    "<br>In order to avoid overfitting that is happening after around 15 epoches, I used data augmentation techniques such as translation along X and Y axis, rotation, resizing etc to increase the amount of data. It will help the model to generalise well.\n",
    "<br>I had to use generators to feed the data to the keras model as large amount of data cannot be loaded in memory at a time. So data will be processed in batches fed by the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "HkS8FjYp_2gi",
    "outputId": "421f48bd-832f-466e-839a-c0adea8d7033"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_end:  37800.0\n",
      "val_end:  42000.0\n"
     ]
    }
   ],
   "source": [
    "#Split the training data to 3 parts- training data, validation data(0.1) and test data(0.1)\n",
    "#Copy the data to 3 different files- training_data.csv, validation_data.csv, testing_data.csv\n",
    "from itertools import islice\n",
    "def copy_data(inputPath, destPath, start, end):  \n",
    "  # open data file in read mode \n",
    "  fn = open(inputPath, 'r') \n",
    "    \n",
    "  # open other file in write mode \n",
    "  fn1 = open(destPath, 'w') \n",
    "    \n",
    "  # read the content of the file line by line \n",
    "  cont = fn.readlines() \n",
    "  type(cont) \n",
    "  for i in range(0, len(cont)): \n",
    "      if(i>=start and i<=end): \n",
    "          fn1.write(cont[i]) \n",
    "      else: \n",
    "          pass\n",
    "    \n",
    "  # close all files \n",
    "  fn.close() \n",
    "  fn1.close()\n",
    "\n",
    "# train_end = df.shape[0]*0.8\n",
    "# val_end = train_end + df.shape[0]*0.1\n",
    "# test_end = val_end + df.shape[0]*0.1\n",
    "\n",
    "# print('train_end: ', train_end)\n",
    "# print('val_end: ', val_end)\n",
    "# print('test_end: ', test_end)\n",
    "\n",
    "train_end = df.shape[0]*0.9\n",
    "val_end = train_end + df.shape[0]*0.1\n",
    "\n",
    "print('train_end: ', train_end)\n",
    "print('val_end: ', val_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2xslqF6tD3EK"
   },
   "outputs": [],
   "source": [
    "train_csv = 'dataset/train.csv'\n",
    "training_data_path = 'dataset/training_data.csv'\n",
    "validation_data_path = 'dataset/validation_data.csv'\n",
    "testing_data_path = 'dataset/testing_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1t1t9Y8BFUrG"
   },
   "outputs": [],
   "source": [
    "copy_data(train_csv,training_data_path, 1, train_end)\n",
    "copy_data(train_csv,validation_data_path, train_end+1, val_end)\n",
    "# copy_data(train_csv,testing_data_path, val_end+1, test_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxv0eN6b8137"
   },
   "source": [
    "Pick up some all from training data and apply the following:\n",
    "<br>1. Rotating image by an angle between (0-30)deg randomly and zoom by 10%\n",
    "<br>2. Shift the image horizontally by 10% of the width \n",
    "<br>3. Shift the image vertically by 10% of the height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kTntpkvCZscb"
   },
   "outputs": [],
   "source": [
    "#Data augmentation using opencv\n",
    "import cv2\n",
    "def rotate_image(image, angle, scale):\n",
    "  # plt.subplot(1, 2, 1)\n",
    "  # plt.imshow(image, cmap='Greys', interpolation=None)\n",
    "  # plt.title('Augmentation')\n",
    "  # plt.ylabel('Original')\n",
    "  \n",
    "  w = image.shape[1]\n",
    "  h = image.shape[0]\n",
    "  #rotate matrix\n",
    "  M = cv2.getRotationMatrix2D((w/2,h/2), angle, scale)\n",
    "  #rotate\n",
    "  image = cv2.warpAffine(image,M,(w,h))\n",
    "\n",
    "  # plt.subplot(1, 2, 2)\n",
    "  # plt.imshow(image, cmap='Greys', interpolation=None)\n",
    "  # plt.ylabel('Rotated')\n",
    "  # plt.show()\n",
    "  image = (image.reshape(28,28,1))/255.0\n",
    "\n",
    "  return image\n",
    "\n",
    "def translate_in_X(image, tx):\n",
    "  # plt.subplot(1, 2, 1)\n",
    "  # plt.imshow(image, cmap='Greys', interpolation=None)\n",
    "  # plt.title('Augmentation')\n",
    "  # plt.ylabel('Original')\n",
    "  rows,cols = image.shape\n",
    "  M = np.float32([[1,0,tx],[0,1,0]])\n",
    "  # print(\"m: \", M)\n",
    "  image = cv2.warpAffine(image,M,(cols,rows))\n",
    "\n",
    "  # plt.subplot(1, 2, 2)\n",
    "  # plt.imshow(image, cmap='Greys', interpolation=None)\n",
    "  # plt.ylabel('Rotated')\n",
    "  # plt.show()\n",
    "  image = (image.reshape(28,28,1))/255.0\n",
    "  return image\n",
    "\n",
    "def translate_in_Y(image, ty):\n",
    "  rows,cols = image.shape\n",
    "  M = np.float32([[1,0,0],[0,1,ty]])\n",
    "  image = cv2.warpAffine(image,M,(cols,rows))\n",
    "  image = (image.reshape(28,28,1))/255.0\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_242wpGGbHHs",
    "outputId": "d01f3e5b-fdc2-42a7-c8ec-52048d8c4b7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "f = open(training_data_path, \"r\")\n",
    "line = f.readline()\n",
    "line = line.strip().split(\",\")\n",
    "image = np.asfarray(line[1:]).reshape(28,28)\n",
    "image = translate_in_X(image,1)\n",
    "image = image.reshape(28,28,1)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YxysnTXSDutu"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def augment_data(image):\n",
    "  images = []\n",
    "  angle = random.uniform(0,30)\n",
    "  scale = random.uniform(1,2)\n",
    "  tx = random.uniform(0,3)\n",
    "  ty = random.uniform(0,3)\n",
    "  images.append(rotate_image(image, random.uniform(0,30), random.uniform(1,2)))\n",
    "  images.append(rotate_image(image, random.uniform(0,30), random.uniform(1,2)))\n",
    "  images.append(rotate_image(image, random.uniform(0,30), random.uniform(1,2)))\n",
    "  images.append(translate_in_X(image, tx))\n",
    "  images.append(translate_in_Y(image, ty))\n",
    "  return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Do5JIEjPBATC"
   },
   "outputs": [],
   "source": [
    "#Image generator\n",
    "def csv_to_image_generator(dataPath, batch_size, mode):\n",
    "\n",
    "  #Open the csv file in read mode\n",
    "  f = open(dataPath, \"r\")\n",
    "  while True:\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    while len(images) < batch_size:\n",
    "      line = f.readline()\n",
    "      \n",
    "      if line == \"\":\n",
    "        f.seek(0)\n",
    "        line = f.readline()\n",
    "\n",
    "      line = line.strip().split(\",\")\n",
    "      tmp = [0 for i in range(10)]\n",
    "      tmp[int(line[0])] = 1\n",
    "\n",
    "      image = (np.asfarray(line[1:]).reshape(28,28))\n",
    "      if mode=='train':\n",
    "        images += augment_data(image)\n",
    "        for i in range(0,5): \n",
    "          labels.append(tmp)\n",
    "\n",
    "      image = (image.reshape(28,28,1)) / 255.0\n",
    "      \n",
    "      #print(\"shape:\",np.shape(image))\n",
    "      #print(\"shape of tmp:\", np.shape(tmp))\n",
    "      images.append(image)\n",
    "      labels.append(tmp)\n",
    "\n",
    "    #print(\"shape of images:\", np.shape(images))\n",
    "    #print(\"shape of labels:\", np.shape(labels)) \n",
    "    yield(np.array(images), np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hfdaWaZ-e0Xs"
   },
   "outputs": [],
   "source": [
    "#Testing image generator\n",
    "def csv_to_image_test_generator(dataPath, batch_size, mode):\n",
    "\n",
    "  #Open the csv file in read mode\n",
    "  f = open(dataPath, \"r\")\n",
    "  _ = f.readline()\n",
    "  while True:\n",
    "    images = []\n",
    "\n",
    "    while len(images) < batch_size:\n",
    "      line = f.readline()\n",
    "      \n",
    "      if line == \"\":\n",
    "        f.seek(0)\n",
    "        _ = f.readline()\n",
    "        line = f.readline()\n",
    "\n",
    "      line = line.strip().split(\",\")\n",
    "      image = (np.asfarray(line).reshape(28,28,1))/255.0\n",
    "      \n",
    "      #print(\"shape:\",np.shape(image))\n",
    "      #print(\"shape of tmp:\", np.shape(tmp))\n",
    "      images.append(image)\n",
    "\n",
    "    #print(\"shape of images:\", np.shape(images))\n",
    "    #print(\"shape of labels:\", np.shape(labels)) \n",
    "    yield(np.array(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tGAa2lWpSTJN"
   },
   "outputs": [],
   "source": [
    "train_data = 'dataset/training_data.csv'\n",
    "val_data = 'dataset/validation_data.csv'\n",
    "# test_data = '/content/drive/My Drive/Colab Notebooks/digit-recognizer/testing_data.csv'\n",
    "batch_size = 32\n",
    "train_gen = csv_to_image_generator(train_data, batch_size, 'train')\n",
    "val_gen = csv_to_image_generator(val_data, batch_size, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_DBq7l9dU5Ky"
   },
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1naXhNKIRngE"
   },
   "outputs": [],
   "source": [
    "#Model-2\n",
    "model2 = Sequential()\n",
    "model2.add(Conv2D(32, kernel_size=3, activation='relu', input_shape=(28, 28, 1), padding='same'))\n",
    "model2.add(Conv2D(64, kernel_size=3, activation='relu', padding='same'))\n",
    "model2.add(MaxPool2D(pool_size=(2,2)))\n",
    "model2.add(BatchNormalization(axis=-1))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model2.add(Conv2D(128, kernel_size=3, activation='relu', padding='same'))\n",
    "model2.add(Conv2D(128, kernel_size=3, activation='relu', padding='same'))\n",
    "model2.add(MaxPool2D(pool_size=(2,2)))\n",
    "model2.add(BatchNormalization(axis=-1))\n",
    "#model.add(Dropout(0.5))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model2.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "PCMdzjzZRn1U",
    "outputId": "e71eb0dc-2f47-42b0-b24f-edfd3e7c8ab5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_26 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               1605888   \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,849,482\n",
      "Trainable params: 1,849,098\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2SVuI4bqSkZn"
   },
   "outputs": [],
   "source": [
    "callbacks = [ModelCheckpoint('model/best_with_gen.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "31ZKDHgEJlVu",
    "outputId": "d1c0310d-9b34-43c4-ed9e-901bbb4b81b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1181/1181 [==============================] - 16s 13ms/step - loss: 0.3020 - acc: 0.9140 - val_loss: 0.2365 - val_acc: 0.9506\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.23646, saving model to /content/drive/My Drive/Colab Notebooks/digit-recognizer/best_with_gen.h5\n",
      "Epoch 2/50\n",
      "1181/1181 [==============================] - 14s 12ms/step - loss: 0.1486 - acc: 0.9574 - val_loss: 0.1048 - val_acc: 0.9678\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.23646 to 0.10483, saving model to /content/drive/My Drive/Colab Notebooks/digit-recognizer/best_with_gen.h5\n",
      "Epoch 3/50\n",
      "1181/1181 [==============================] - 14s 12ms/step - loss: 0.1041 - acc: 0.9699 - val_loss: 0.0968 - val_acc: 0.9714\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.10483 to 0.09679, saving model to /content/drive/My Drive/Colab Notebooks/digit-recognizer/best_with_gen.h5\n",
      "Epoch 4/50\n",
      "1181/1181 [==============================] - 14s 12ms/step - loss: 0.0961 - acc: 0.9721 - val_loss: 0.0536 - val_acc: 0.9862\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.09679 to 0.05365, saving model to /content/drive/My Drive/Colab Notebooks/digit-recognizer/best_with_gen.h5\n",
      "Epoch 5/50\n",
      "1181/1181 [==============================] - 14s 12ms/step - loss: 0.0836 - acc: 0.9747 - val_loss: 0.0516 - val_acc: 0.9866\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.05365 to 0.05158, saving model to /content/drive/My Drive/Colab Notebooks/digit-recognizer/best_with_gen.h5\n",
      "Epoch 6/50\n",
      "1181/1181 [==============================] - 14s 12ms/step - loss: 0.0858 - acc: 0.9762 - val_loss: 0.0594 - val_acc: 0.9843\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.05158\n",
      "Epoch 7/50\n",
      "1181/1181 [==============================] - 14s 12ms/step - loss: 0.0671 - acc: 0.9811 - val_loss: 0.0345 - val_acc: 0.9895\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.05158 to 0.03451, saving model to /content/drive/My Drive/Colab Notebooks/digit-recognizer/best_with_gen.h5\n",
      "Epoch 8/50\n",
      "1181/1181 [==============================] - 14s 12ms/step - loss: 0.0705 - acc: 0.9800 - val_loss: 0.0344 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.03451 to 0.03443, saving model to /content/drive/My Drive/Colab Notebooks/digit-recognizer/best_with_gen.h5\n",
      "Epoch 9/50\n",
      "1181/1181 [==============================] - 15s 12ms/step - loss: 0.0587 - acc: 0.9836 - val_loss: 0.0393 - val_acc: 0.9869\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.03443\n",
      "Epoch 10/50\n",
      "1181/1181 [==============================] - 15s 13ms/step - loss: 0.0522 - acc: 0.9843 - val_loss: 0.0305 - val_acc: 0.9921\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.03443 to 0.03047, saving model to /content/drive/My Drive/Colab Notebooks/digit-recognizer/best_with_gen.h5\n",
      "Epoch 11/50\n",
      "1181/1181 [==============================] - 15s 12ms/step - loss: 0.0491 - acc: 0.9860 - val_loss: 0.0365 - val_acc: 0.9900\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.03047\n",
      "Epoch 12/50\n",
      "1181/1181 [==============================] - 14s 12ms/step - loss: 0.0457 - acc: 0.9867 - val_loss: 0.0581 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.03047\n",
      "Epoch 13/50\n",
      "1181/1181 [==============================] - 15s 12ms/step - loss: 0.0535 - acc: 0.9847 - val_loss: 0.0522 - val_acc: 0.9871\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.03047\n",
      "Epoch 14/50\n",
      "1181/1181 [==============================] - 15s 12ms/step - loss: 0.0416 - acc: 0.9874 - val_loss: 0.0418 - val_acc: 0.9909\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.03047\n",
      "Epoch 15/50\n",
      "1181/1181 [==============================] - 14s 12ms/step - loss: 0.0429 - acc: 0.9880 - val_loss: 0.0315 - val_acc: 0.9909\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.03047\n",
      "Epoch 16/50\n",
      "1181/1181 [==============================] - 15s 12ms/step - loss: 0.0408 - acc: 0.9884 - val_loss: 0.0669 - val_acc: 0.9845\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.03047\n",
      "Epoch 17/50\n",
      "1181/1181 [==============================] - 14s 12ms/step - loss: 0.0379 - acc: 0.9887 - val_loss: 0.0277 - val_acc: 0.9933\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.03047 to 0.02774, saving model to /content/drive/My Drive/Colab Notebooks/digit-recognizer/best_with_gen.h5\n",
      "Epoch 18/50\n",
      "1181/1181 [==============================] - 15s 12ms/step - loss: 0.0343 - acc: 0.9899 - val_loss: 0.0287 - val_acc: 0.9917\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.02774\n",
      "Epoch 19/50\n",
      "1181/1181 [==============================] - 15s 12ms/step - loss: 0.0393 - acc: 0.9889 - val_loss: 0.0413 - val_acc: 0.9909\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.02774\n",
      "Epoch 20/50\n",
      "1181/1181 [==============================] - 14s 12ms/step - loss: 0.0364 - acc: 0.9901 - val_loss: 0.0439 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.02774\n",
      "Epoch 21/50\n",
      "1181/1181 [==============================] - 14s 12ms/step - loss: 0.0244 - acc: 0.9919 - val_loss: 0.0329 - val_acc: 0.9921\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.02774\n",
      "Epoch 22/50\n",
      "1181/1181 [==============================] - 15s 12ms/step - loss: 0.0302 - acc: 0.9914 - val_loss: 0.0393 - val_acc: 0.9895\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.02774\n",
      "Epoch 23/50\n",
      "1181/1181 [==============================] - 14s 12ms/step - loss: 0.0242 - acc: 0.9924 - val_loss: 0.0382 - val_acc: 0.9905\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.02774\n",
      "Epoch 24/50\n",
      "1181/1181 [==============================] - 14s 12ms/step - loss: 0.0332 - acc: 0.9909 - val_loss: 0.0482 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.02774\n",
      "Epoch 25/50\n",
      "1181/1181 [==============================] - 15s 12ms/step - loss: 0.0297 - acc: 0.9915 - val_loss: 0.0587 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.02774\n",
      "Epoch 26/50\n",
      "1181/1181 [==============================] - 15s 12ms/step - loss: 0.0200 - acc: 0.9939 - val_loss: 0.0346 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.02774\n",
      "Epoch 27/50\n",
      "1181/1181 [==============================] - 15s 12ms/step - loss: 0.0250 - acc: 0.9933 - val_loss: 0.0429 - val_acc: 0.9924\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.02774\n",
      "Epoch 28/50\n",
      "1181/1181 [==============================] - 14s 12ms/step - loss: 0.0264 - acc: 0.9924 - val_loss: 0.0378 - val_acc: 0.9921\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.02774\n",
      "Epoch 29/50\n",
      "1181/1181 [==============================] - 14s 12ms/step - loss: 0.0289 - acc: 0.9922 - val_loss: 0.0375 - val_acc: 0.9921\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.02774\n",
      "Epoch 30/50\n",
      "1181/1181 [==============================] - 15s 12ms/step - loss: 0.0216 - acc: 0.9937 - val_loss: 0.0395 - val_acc: 0.9924\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.02774\n",
      "Epoch 31/50\n",
      "1181/1181 [==============================] - 15s 12ms/step - loss: 0.0253 - acc: 0.9925 - val_loss: 0.0393 - val_acc: 0.9933\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.02774\n",
      "Epoch 32/50\n",
      "1181/1181 [==============================] - 15s 12ms/step - loss: 0.0216 - acc: 0.9948 - val_loss: 0.0278 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.02774\n",
      "Epoch 33/50\n",
      "1181/1181 [==============================] - 14s 12ms/step - loss: 0.0210 - acc: 0.9938 - val_loss: 0.0293 - val_acc: 0.9933\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.02774\n",
      "Epoch 34/50\n",
      "1181/1181 [==============================] - 15s 12ms/step - loss: 0.0211 - acc: 0.9938 - val_loss: 0.0387 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.02774\n",
      "Epoch 35/50\n",
      "1181/1181 [==============================] - 15s 12ms/step - loss: 0.0235 - acc: 0.9935 - val_loss: 0.0379 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.02774\n",
      "Epoch 36/50\n",
      "1181/1181 [==============================] - 14s 12ms/step - loss: 0.0251 - acc: 0.9933 - val_loss: 0.0457 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.02774\n",
      "Epoch 37/50\n",
      "1181/1181 [==============================] - 14s 12ms/step - loss: 0.0149 - acc: 0.9952 - val_loss: 0.0358 - val_acc: 0.9924\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.02774\n",
      "Epoch 38/50\n",
      "1181/1181 [==============================] - 14s 12ms/step - loss: 0.0246 - acc: 0.9931 - val_loss: 0.0385 - val_acc: 0.9926\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.02774\n",
      "Epoch 39/50\n",
      "1181/1181 [==============================] - 14s 12ms/step - loss: 0.0154 - acc: 0.9956 - val_loss: 0.0292 - val_acc: 0.9950\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.02774\n",
      "Epoch 40/50\n",
      "1181/1181 [==============================] - 15s 12ms/step - loss: 0.0235 - acc: 0.9938 - val_loss: 0.0469 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.02774\n",
      "Epoch 41/50\n",
      "1181/1181 [==============================] - 14s 12ms/step - loss: 0.0218 - acc: 0.9938 - val_loss: 0.0346 - val_acc: 0.9928\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.02774\n",
      "Epoch 42/50\n",
      "1181/1181 [==============================] - 14s 12ms/step - loss: 0.0173 - acc: 0.9945 - val_loss: 0.0322 - val_acc: 0.9919\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.02774\n",
      "Epoch 43/50\n",
      "1181/1181 [==============================] - 14s 12ms/step - loss: 0.0187 - acc: 0.9951 - val_loss: 0.0435 - val_acc: 0.9907\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.02774\n",
      "Epoch 44/50\n",
      "1181/1181 [==============================] - 14s 12ms/step - loss: 0.0170 - acc: 0.9944 - val_loss: 0.0406 - val_acc: 0.9919\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.02774\n",
      "Epoch 45/50\n",
      "1181/1181 [==============================] - 15s 12ms/step - loss: 0.0218 - acc: 0.9939 - val_loss: 0.0257 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.02774 to 0.02571, saving model to /content/drive/My Drive/Colab Notebooks/digit-recognizer/best_with_gen.h5\n",
      "Epoch 46/50\n",
      "1181/1181 [==============================] - 14s 12ms/step - loss: 0.0161 - acc: 0.9948 - val_loss: 0.0386 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.02571\n",
      "Epoch 47/50\n",
      "1181/1181 [==============================] - 14s 12ms/step - loss: 0.0188 - acc: 0.9944 - val_loss: 0.0243 - val_acc: 0.9945\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.02571 to 0.02433, saving model to /content/drive/My Drive/Colab Notebooks/digit-recognizer/best_with_gen.h5\n",
      "Epoch 48/50\n",
      "1181/1181 [==============================] - 14s 12ms/step - loss: 0.0157 - acc: 0.9960 - val_loss: 0.0407 - val_acc: 0.9900\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.02433\n",
      "Epoch 49/50\n",
      "1181/1181 [==============================] - 14s 12ms/step - loss: 0.0150 - acc: 0.9954 - val_loss: 0.0360 - val_acc: 0.9933\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.02433\n",
      "Epoch 50/50\n",
      "1181/1181 [==============================] - 14s 12ms/step - loss: 0.0134 - acc: 0.9964 - val_loss: 0.0330 - val_acc: 0.9945\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.02433\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit_generator(train_gen, steps_per_epoch=train_end//batch_size, validation_data=val_gen, validation_steps= (val_end-train_end)// batch_size, epochs=50, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "1pEiMSR7PRu4",
    "outputId": "e62ee248-988a-4b52-dc21-accc46656e03"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3P8DitKAarfxzkwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZhFyhIQjP7c4"
   },
   "outputs": [],
   "source": [
    "# predict results\n",
    "testing_data = '../dataset/test.csv'\n",
    "test_gen = csv_to_image_test_generator(testing_data, batch_size, None)\n",
    "results = model2.predict_generator(test_gen, steps=df_test.shape[0]//batch_size)\n",
    "# select the index with maximum probability\n",
    "results = np.argmax(results,axis = 1)\n",
    "results = pd.Series(results,name=\"Label\")\n",
    "submit = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "submit.to_csv(\"submission/mnist_predictions_using_gen.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fcErg-BuepuB"
   },
   "source": [
    "<img src='submission/mnist_submission_2.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "digit-recognizer",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
