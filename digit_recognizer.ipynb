{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "PEtEFFv0g23A",
    "outputId": "b53e6f48-157c-4633-ca8e-80a845988b58"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.layers import Conv2D, Dense, MaxPool2D, BatchNormalization, Flatten, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZvDr1jF4hJ-s"
   },
   "outputs": [],
   "source": [
    "#Load the training and test data\n",
    "df = pd.read_csv('../dataset/train.csv')\n",
    "df_test = pd.read_csv('../dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "colab_type": "code",
    "id": "OfiDoEbfiQ_j",
    "outputId": "624ff358-74be-48bb-b45d-9b74a6dba2dd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>pixel11</th>\n",
       "      <th>pixel12</th>\n",
       "      <th>pixel13</th>\n",
       "      <th>pixel14</th>\n",
       "      <th>pixel15</th>\n",
       "      <th>pixel16</th>\n",
       "      <th>pixel17</th>\n",
       "      <th>pixel18</th>\n",
       "      <th>pixel19</th>\n",
       "      <th>pixel20</th>\n",
       "      <th>pixel21</th>\n",
       "      <th>pixel22</th>\n",
       "      <th>pixel23</th>\n",
       "      <th>pixel24</th>\n",
       "      <th>pixel25</th>\n",
       "      <th>pixel26</th>\n",
       "      <th>pixel27</th>\n",
       "      <th>pixel28</th>\n",
       "      <th>pixel29</th>\n",
       "      <th>pixel30</th>\n",
       "      <th>pixel31</th>\n",
       "      <th>pixel32</th>\n",
       "      <th>pixel33</th>\n",
       "      <th>pixel34</th>\n",
       "      <th>pixel35</th>\n",
       "      <th>pixel36</th>\n",
       "      <th>pixel37</th>\n",
       "      <th>pixel38</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel744</th>\n",
       "      <th>pixel745</th>\n",
       "      <th>pixel746</th>\n",
       "      <th>pixel747</th>\n",
       "      <th>pixel748</th>\n",
       "      <th>pixel749</th>\n",
       "      <th>pixel750</th>\n",
       "      <th>pixel751</th>\n",
       "      <th>pixel752</th>\n",
       "      <th>pixel753</th>\n",
       "      <th>pixel754</th>\n",
       "      <th>pixel755</th>\n",
       "      <th>pixel756</th>\n",
       "      <th>pixel757</th>\n",
       "      <th>pixel758</th>\n",
       "      <th>pixel759</th>\n",
       "      <th>pixel760</th>\n",
       "      <th>pixel761</th>\n",
       "      <th>pixel762</th>\n",
       "      <th>pixel763</th>\n",
       "      <th>pixel764</th>\n",
       "      <th>pixel765</th>\n",
       "      <th>pixel766</th>\n",
       "      <th>pixel767</th>\n",
       "      <th>pixel768</th>\n",
       "      <th>pixel769</th>\n",
       "      <th>pixel770</th>\n",
       "      <th>pixel771</th>\n",
       "      <th>pixel772</th>\n",
       "      <th>pixel773</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  ...  pixel780  pixel781  pixel782  pixel783\n",
       "0      1       0       0       0  ...         0         0         0         0\n",
       "1      0       0       0       0  ...         0         0         0         0\n",
       "2      1       0       0       0  ...         0         0         0         0\n",
       "3      4       0       0       0  ...         0         0         0         0\n",
       "4      0       0       0       0  ...         0         0         0         0\n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "HXX8BUMbi9M_",
    "outputId": "9e82f50f-ba6e-471f-cc51-62704d066c3d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert dataframe to input(X_train) and output label(Y_train) format where input is the values of all the 28x28 pixels in all the images and output label is the actual digit the image represents.\n",
    "Y_train = df['label']\n",
    "X_train = df.drop(labels=['label'],axis=1)\n",
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xNrbpen_kprk",
    "outputId": "2ff6c51f-c4d3-41a5-afcc-1b0f272d8da6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check null values in the labels\n",
    "Y_train.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "p3twKv41lFGQ",
    "outputId": "7e0fef0d-b01f-45a4-fde2-548dbb33d458"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check null values in the pixel data\n",
    "X_train.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JNdgYIXPnuC8"
   },
   "outputs": [],
   "source": [
    "#Normalise the data\n",
    "X_train = X_train/255\n",
    "df_test = df_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ApW_DdJ8rj0S"
   },
   "source": [
    "The CNN Models converge faster on data in (0,1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XmQ7_pxLpSa_"
   },
   "outputs": [],
   "source": [
    "#Convert pixel data to 28x28x1 image\n",
    "X_train_reshape = X_train.values.reshape(-1,28,28,1)\n",
    "df_test = df_test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Q31PmuRrSlh"
   },
   "source": [
    " The data of each image is given as 1D array of 784 values. This 1D array is converted to 3D greyscale image using reshape. The reshape function has first param as -1 as the number of rows are unknown. The dimension of each image is 28x28x1. The 1 represents number of channels in greyscale image. For RGB the number of channels is 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "C3YcRzyFwYaR",
    "outputId": "394d8d21-8de7-4ee4-e5c2-7c58bcb1bc74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 28, 28, 1)\n",
      "(28000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train_reshape))\n",
    "print(np.shape(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "colab_type": "code",
    "id": "A6u0xfUApeLj",
    "outputId": "677415fd-096c-4cde-b1a6-b573e7dbf9a7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdUAAAHSCAYAAAC6vFFPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 1296x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train_reshape[0], cmap='Greys', interpolation=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bgRFtiKK24N4"
   },
   "outputs": [],
   "source": [
    "#Convert categorical data to one hot encoding using keras\n",
    "Y_train = to_categorical(Y_train, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CpEMIrj8rdIW"
   },
   "source": [
    "The digits 0-9 repesent categorical data. They are converted to one-hot-encoded vectors. This is done to achieve output in the form of probabilites for each class. The class with maximum probability is given as predicted output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "T8bh1Tn53TLQ",
    "outputId": "e4b9370c-f63d-4a3d-e342-1fe3a44770bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k1u719HwlO9I"
   },
   "outputs": [],
   "source": [
    "#Create test dataset from the training data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train_reshape, Y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "wNabgYG89LUy",
    "outputId": "76c43454-3a48-41a9-ea95-e3a13ee4669f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (37800, 28, 28, 1)\n",
      "X_test shape: (4200, 28, 28, 1)\n",
      "Y_train shape: (37800, 10)\n",
      "Y_test shape: (4200, 10)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print('Y_test shape:', Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0tf5j1brtHps"
   },
   "source": [
    "**CNN Model**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Bedhd7k1pCH"
   },
   "outputs": [],
   "source": [
    "#CNN Model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu', input_shape=(28, 28, 1), padding='same'))\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation = \"relu\"))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "eBqMvJlD6mC3",
    "outputId": "b4e040a3-94ae-43a7-94f2-24ae9c199a19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "cBs1bacS8POu",
    "outputId": "dc932f09-56f5-412b-ad61-9b4dc7d38ac9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                200736    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 293,738\n",
      "Trainable params: 293,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LrnNZVyG1NdY"
   },
   "source": [
    "Early stopping is used for the model. It enables us to specifiy more number of epoches for training but it stops training once the model doesn't improve further with a patience of a specified number of epoches.\n",
    "Model Checkpoints are used to save the model weights after each epoch if the val_loss is decreased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X5tDGVXpS2T_"
   },
   "outputs": [],
   "source": [
    "# callbacks = [ModelCheckpoint('/content/drive/My Drive/Colab Notebooks/digit-recognizer/best.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False),\n",
    "#              EarlyStopping(patience=3, monitor='val_loss', verbose=1)]\n",
    "callbacks = [ModelCheckpoint('/content/drive/My Drive/Colab Notebooks/digit-recognizer/best.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "EbZxTbKg8Rfn",
    "outputId": "79a0bb9a-e878-4981-dd1e-7fd5986aa836"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34020 samples, validate on 3780 samples\n",
      "Epoch 1/30\n",
      "34020/34020 [==============================] - 6s 169us/step - loss: 0.0118 - acc: 0.9961 - val_loss: 0.0629 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06292, saving model to /content/drive/My Drive/Colab Notebooks/digit-recognizer/best.h5\n",
      "Epoch 2/30\n",
      "34020/34020 [==============================] - 6s 170us/step - loss: 0.0097 - acc: 0.9971 - val_loss: 0.0632 - val_acc: 0.9862\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.06292\n",
      "Epoch 3/30\n",
      "34020/34020 [==============================] - 6s 171us/step - loss: 0.0082 - acc: 0.9972 - val_loss: 0.0628 - val_acc: 0.9868\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.06292 to 0.06277, saving model to /content/drive/My Drive/Colab Notebooks/digit-recognizer/best.h5\n",
      "Epoch 4/30\n",
      "34020/34020 [==============================] - 6s 168us/step - loss: 0.0082 - acc: 0.9971 - val_loss: 0.0627 - val_acc: 0.9868\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.06277 to 0.06274, saving model to /content/drive/My Drive/Colab Notebooks/digit-recognizer/best.h5\n",
      "Epoch 5/30\n",
      "34020/34020 [==============================] - 6s 169us/step - loss: 0.0069 - acc: 0.9979 - val_loss: 0.0646 - val_acc: 0.9876\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06274\n",
      "Epoch 6/30\n",
      "34020/34020 [==============================] - 6s 169us/step - loss: 0.0074 - acc: 0.9976 - val_loss: 0.0639 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.06274\n",
      "Epoch 7/30\n",
      "34020/34020 [==============================] - 6s 167us/step - loss: 0.0077 - acc: 0.9974 - val_loss: 0.0533 - val_acc: 0.9878\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.06274 to 0.05327, saving model to /content/drive/My Drive/Colab Notebooks/digit-recognizer/best.h5\n",
      "Epoch 8/30\n",
      "34020/34020 [==============================] - 6s 169us/step - loss: 0.0036 - acc: 0.9991 - val_loss: 0.0687 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05327\n",
      "Epoch 9/30\n",
      "34020/34020 [==============================] - 6s 169us/step - loss: 0.0072 - acc: 0.9981 - val_loss: 0.0611 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.05327\n",
      "Epoch 10/30\n",
      "34020/34020 [==============================] - 6s 169us/step - loss: 0.0048 - acc: 0.9987 - val_loss: 0.0661 - val_acc: 0.9878\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05327\n",
      "Epoch 11/30\n",
      "34020/34020 [==============================] - 6s 168us/step - loss: 0.0047 - acc: 0.9987 - val_loss: 0.0584 - val_acc: 0.9899\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.05327\n",
      "Epoch 12/30\n",
      "34020/34020 [==============================] - 6s 169us/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0739 - val_acc: 0.9897\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.05327\n",
      "Epoch 13/30\n",
      "34020/34020 [==============================] - 6s 172us/step - loss: 0.0072 - acc: 0.9980 - val_loss: 0.0430 - val_acc: 0.9892\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.05327 to 0.04296, saving model to /content/drive/My Drive/Colab Notebooks/digit-recognizer/best.h5\n",
      "Epoch 14/30\n",
      "34020/34020 [==============================] - 6s 173us/step - loss: 0.0046 - acc: 0.9986 - val_loss: 0.0629 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.04296\n",
      "Epoch 15/30\n",
      "34020/34020 [==============================] - 6s 176us/step - loss: 0.0036 - acc: 0.9990 - val_loss: 0.0594 - val_acc: 0.9897\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.04296\n",
      "Epoch 16/30\n",
      "34020/34020 [==============================] - 6s 171us/step - loss: 0.0035 - acc: 0.9990 - val_loss: 0.0621 - val_acc: 0.9881\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.04296\n",
      "Epoch 17/30\n",
      "34020/34020 [==============================] - 6s 170us/step - loss: 0.0035 - acc: 0.9992 - val_loss: 0.0711 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.04296\n",
      "Epoch 18/30\n",
      "34020/34020 [==============================] - 6s 171us/step - loss: 0.0055 - acc: 0.9985 - val_loss: 0.0587 - val_acc: 0.9897\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.04296\n",
      "Epoch 19/30\n",
      "34020/34020 [==============================] - 6s 169us/step - loss: 0.0050 - acc: 0.9985 - val_loss: 0.0483 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.04296\n",
      "Epoch 20/30\n",
      "34020/34020 [==============================] - 6s 168us/step - loss: 0.0045 - acc: 0.9985 - val_loss: 0.0813 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.04296\n",
      "Epoch 21/30\n",
      "34020/34020 [==============================] - 6s 168us/step - loss: 0.0029 - acc: 0.9994 - val_loss: 0.0812 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.04296\n",
      "Epoch 22/30\n",
      "34020/34020 [==============================] - 6s 168us/step - loss: 0.0044 - acc: 0.9989 - val_loss: 0.0604 - val_acc: 0.9907\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.04296\n",
      "Epoch 23/30\n",
      "34020/34020 [==============================] - 6s 169us/step - loss: 0.0022 - acc: 0.9993 - val_loss: 0.0674 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.04296\n",
      "Epoch 24/30\n",
      "34020/34020 [==============================] - 6s 170us/step - loss: 0.0045 - acc: 0.9990 - val_loss: 0.0848 - val_acc: 0.9894\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.04296\n",
      "Epoch 25/30\n",
      "34020/34020 [==============================] - 6s 168us/step - loss: 0.0023 - acc: 0.9995 - val_loss: 0.1088 - val_acc: 0.9865\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.04296\n",
      "Epoch 26/30\n",
      "34020/34020 [==============================] - 6s 170us/step - loss: 0.0050 - acc: 0.9989 - val_loss: 0.0879 - val_acc: 0.9907\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.04296\n",
      "Epoch 27/30\n",
      "34020/34020 [==============================] - 6s 170us/step - loss: 0.0045 - acc: 0.9989 - val_loss: 0.0901 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.04296\n",
      "Epoch 28/30\n",
      "34020/34020 [==============================] - 6s 169us/step - loss: 0.0029 - acc: 0.9993 - val_loss: 0.1148 - val_acc: 0.9862\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.04296\n",
      "Epoch 29/30\n",
      "34020/34020 [==============================] - 6s 168us/step - loss: 0.0025 - acc: 0.9994 - val_loss: 0.0836 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.04296\n",
      "Epoch 30/30\n",
      "34020/34020 [==============================] - 6s 167us/step - loss: 0.0038 - acc: 0.9991 - val_loss: 0.1059 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.04296\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=30, validation_split=0.1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JnzEYD0GOZI1",
    "outputId": "c4cad328-7564-476e-b08d-024345cd1185"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.999, Test: 0.991\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(X_train, Y_train, verbose=0)\n",
    "_, test_acc = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "tOMoBGo5OeJe",
    "outputId": "806b05a6-9796-4cab-e297-9537740b1007"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAD8CAYAAACW/ATfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUiFAg71SSoWA/w/rh6WjXkjL2wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C3EHjQ7j82un"
   },
   "outputs": [],
   "source": [
    "# predict results\n",
    "results = model.predict(df_test)\n",
    "# select the index with maximum probability\n",
    "results = np.argmax(results,axis = 1)\n",
    "results = pd.Series(results,name=\"Label\")\n",
    "submit = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "submit.to_csv(\"../mnist_predictions.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Do5JIEjPBATC"
   },
   "source": [
    "<img src='/mnist_submission.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "digit-recognizer",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
